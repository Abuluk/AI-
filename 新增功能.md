# æ ¡å›­äºŒæ‰‹äº¤æ˜“å¹³å°æ ¸å¿ƒåŠŸèƒ½æŠ€æœ¯æ–‡æ¡£

## ğŸ“‹ ç›®å½•

- [å•†å®¶åŠŸèƒ½ä¸å•†è´©æ£€æµ‹ç³»ç»Ÿ](#å•†å®¶åŠŸèƒ½ä¸å•†è´©æ£€æµ‹ç³»ç»Ÿ)
- [æ™ºèƒ½æ’åºç³»ç»Ÿ](#æ™ºèƒ½æ’åºç³»ç»Ÿ)
- [å¹¶å‘æ§åˆ¶ä¸æ€§èƒ½ä¼˜åŒ–](#å¹¶å‘æ§åˆ¶ä¸æ€§èƒ½ä¼˜åŒ–)
- [ç³»ç»Ÿæ¶æ„å›¾](#ç³»ç»Ÿæ¶æ„å›¾)
- [æŠ€æœ¯å®ç°ç»†èŠ‚](#æŠ€æœ¯å®ç°ç»†èŠ‚)

---

## å•†å®¶åŠŸèƒ½ä¸å•†è´©æ£€æµ‹ç³»ç»Ÿ

### ğŸª å•†å®¶è®¤è¯ç³»ç»Ÿ

#### åŠŸèƒ½æ¦‚è¿°
å•†å®¶è®¤è¯ç³»ç»Ÿä¸ºå¹³å°æä¾›äº†å®Œæ•´çš„å•†å®¶ç”Ÿæ€ç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬å•†å®¶ç”³è¯·ã€å®¡æ ¸ã€è®¤è¯çŠ¶æ€ç®¡ç†ç­‰åŠŸèƒ½ã€‚

#### æ ¸å¿ƒç‰¹æ€§
- **ç”³è¯·æµç¨‹**: ç”¨æˆ·ç”³è¯· â†’ ç®¡ç†å‘˜å®¡æ ¸ â†’ è®¤è¯é€šè¿‡
- **è®¤è¯ä¿¡æ¯**: å•†å®¶åç§°ã€è¥ä¸šæ‰§ç…§ã€è”ç³»æ–¹å¼ã€åœ°å€
- **çŠ¶æ€ç®¡ç†**: pending(å¾…å®¡æ ¸) / approved(å·²è®¤è¯) / rejected(å·²æ‹’ç»)
- **å±•ç¤ºæ§åˆ¶**: æ™ºèƒ½æ§åˆ¶å•†å®¶å•†å“åœ¨å¹³å°ä¸Šçš„å±•ç¤ºé¢‘ç‡

#### æ•°æ®åº“è®¾è®¡
```sql
-- å•†å®¶ä¿¡æ¯è¡¨
CREATE TABLE merchants (
    id INT PRIMARY KEY AUTO_INCREMENT,
    user_id INT NOT NULL,
    merchant_name VARCHAR(100) NOT NULL,
    business_license VARCHAR(200),
    contact_phone VARCHAR(20),
    contact_email VARCHAR(100),
    business_address TEXT,
    status ENUM('pending', 'approved', 'rejected') DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- å•†å®¶å±•ç¤ºé…ç½®è¡¨
CREATE TABLE merchant_display_configs (
    id INT PRIMARY KEY AUTO_INCREMENT,
    user_id INT,
    display_frequency INT DEFAULT 5,  -- æ¯Nä¸ªå•†å“å±•ç¤º1ä¸ªå•†å®¶å•†å“
    is_global BOOLEAN DEFAULT FALSE,  -- æ˜¯å¦ä¸ºå…¨å±€é…ç½®
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);
```

#### APIæ¥å£
```http
POST /api/v1/merchants/apply          # ç”³è¯·å•†å®¶è®¤è¯
GET  /api/v1/merchants/my             # è·å–æˆ‘çš„å•†å®¶ä¿¡æ¯
PUT  /api/v1/merchants/my             # æ›´æ–°æˆ‘çš„å•†å®¶ä¿¡æ¯
GET  /api/v1/merchants/list           # è·å–å•†å®¶åˆ—è¡¨ï¼ˆç®¡ç†å‘˜ï¼‰
PUT  /api/v1/merchants/{id}/approve   # å®¡æ ¸å•†å®¶ç”³è¯·
```

### ğŸ¤– AIå•†è´©æ£€æµ‹ç³»ç»Ÿ

#### åŠŸèƒ½æ¦‚è¿°
åŸºäºAIçš„æ™ºèƒ½å•†è´©æ£€æµ‹ç³»ç»Ÿï¼Œé€šè¿‡åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼ï¼Œè‡ªåŠ¨è¯†åˆ«æ½œåœ¨çš„å•†è´©ç”¨æˆ·ï¼Œç»´æŠ¤å¹³å°ç”Ÿæ€å¹³è¡¡ã€‚

#### æ£€æµ‹æµç¨‹
```mermaid
graph TD
    A[å•†å“ç›‘æ§] --> B[é˜ˆå€¼ç­›é€‰]
    B --> C[è¡Œä¸ºåˆ†æ]
    C --> D[AIåˆ¤æ–­]
    D --> E[è‡ªåŠ¨å¤„ç†]
    
    A1[ç›‘æ§åˆ†ç±»å‰Nä¸ªå•†å“] --> A
    A2[ç›‘æ§é¦–é¡µå‰Nä¸ªå•†å“] --> A
    A3[ç»Ÿè®¡åœ¨å”®å•†å“æ•°é‡] --> A
    
    B1[åœ¨å”®å•†å“æ•° > é˜ˆå€¼] --> B
    
    C1[å‘å¸ƒé¢‘ç‡åˆ†æ] --> C
    C2[åˆ†ç±»åˆ†å¸ƒåˆ†æ] --> C
    C3[ä»·æ ¼èŒƒå›´åˆ†æ] --> C
    C4[å•†ä¸šæ€§è¯æ±‡æ£€æµ‹] --> C
    
    D1[ç§‘å¤§è®¯é£æ˜Ÿç«å¤§æ¨¡å‹] --> D
    
    E1[æ™®é€šç”¨æˆ·ç›´æ¥é€šè¿‡] --> E
    E2[ç–‘ä¼¼å•†è´©è®¾ä¸ºå¾…è®¤è¯] --> E
```

#### æ ¸å¿ƒç®—æ³•
```python
class MerchantDetectionSystem:
    async def analyze_user_behavior(self, user_id: int, days: int = 30) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼"""
        # 1. ç»Ÿè®¡å•†å“æ•°æ®
        total_items = self.db.query(Item).filter(
            and_(
                Item.owner_id == user_id,
                Item.created_at >= start_date
            )
        ).count()
        
        # 2. åˆ†æåˆ†ç±»åˆ†å¸ƒ
        category_stats = self.db.query(
            Item.category,
            func.count(Item.id).label('count')
        ).filter(
            and_(
                Item.owner_id == user_id,
                Item.created_at >= start_date
            )
        ).group_by(Item.category).all()
        
        # 3. åˆ†æä»·æ ¼åˆ†å¸ƒ
        price_stats = self.db.query(
            func.avg(Item.price).label('avg_price'),
            func.min(Item.price).label('min_price'),
            func.max(Item.price).label('max_price')
        ).filter(
            and_(
                Item.owner_id == user_id,
                Item.created_at >= start_date
            )
        ).first()
        
        return {
            "total_items": total_items,
            "category_distribution": category_stats,
            "price_statistics": price_stats,
            # ... æ›´å¤šåˆ†ææ•°æ®
        }
    
    async def get_ai_judgment(self, behavior_data: Dict[str, Any]) -> Dict[str, Any]:
        """AIåˆ¤æ–­æ˜¯å¦ä¸ºå•†è´©"""
        prompt = f"""
        åˆ†æä»¥ä¸‹ç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºå•†è´©ï¼š
        
        å•†å“æ€»æ•°: {behavior_data['total_items']}
        åˆ†ç±»åˆ†å¸ƒ: {behavior_data['category_distribution']}
        ä»·æ ¼ç»Ÿè®¡: {behavior_data['price_statistics']}
        
        è¯·ä»ä»¥ä¸‹ç»´åº¦åˆ†æï¼š
        1. å‘å¸ƒé¢‘ç‡æ˜¯å¦å¼‚å¸¸
        2. åˆ†ç±»åˆ†å¸ƒæ˜¯å¦è¿‡äºé›†ä¸­
        3. ä»·æ ¼èŒƒå›´æ˜¯å¦åˆç†
        4. æ˜¯å¦å­˜åœ¨å•†ä¸šæ€§ç‰¹å¾
        
        è¿”å›JSONæ ¼å¼ï¼š
        {{
            "is_merchant": true/false,
            "confidence": 0.0-1.0,
            "reason": "åˆ†æç†ç”±"
        }}
        """
        
        # è°ƒç”¨ç§‘å¤§è®¯é£æ˜Ÿç«å¤§æ¨¡å‹
        ai_result = await self.spark_ai.analyze_text(prompt)
        return ai_result
```

#### é…ç½®å‚æ•°
| å‚æ•°å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| monitor_top_n | 50 | ç›‘æ§æ¯ä¸ªåˆ†ç±»å’Œé¦–é¡µæ’åºå‰Nä¸ªå•†å“ |
| threshold_items | 10 | åœ¨å”®å•†å“æ•°é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤æ•°é‡å°†è¿›è¡ŒAIåˆ†æ |
| analysis_days | 30 | åˆ†æç”¨æˆ·æœ€è¿‘Nå¤©çš„è¡Œä¸ºæ•°æ® |
| ai_confidence_threshold | 0.7 | AIåˆ¤æ–­ä¸ºå•†è´©çš„ç½®ä¿¡åº¦é˜ˆå€¼ |
| auto_set_pending | true | è¯†åˆ«å‡ºå•†è´©åè‡ªåŠ¨è®¾ä¸ºå¾…è®¤è¯çŠ¶æ€ |

#### å®šæ—¶ä»»åŠ¡
```python
# æ¯å¤©å‡Œæ™¨2ç‚¹è‡ªåŠ¨æ‰§è¡Œå•†è´©æ£€æµ‹
@scheduler.scheduled_job('cron', hour=2, minute=0)
async def merchant_detection_task():
    """å®šæ—¶å•†è´©æ£€æµ‹ä»»åŠ¡"""
    detection_system = MerchantDetectionSystem(db)
    results = await detection_system.detect_merchants(
        top_n=50,
        threshold_items=10,
        analysis_days=30
    )
    logger.info(f"æ£€æµ‹åˆ° {len(results)} ä¸ªæ½œåœ¨å•†è´©")
```

---

## æ™ºèƒ½æ’åºç³»ç»Ÿ

### ğŸ“Š æ—¶åºåŠ¨æ€æƒé‡ç®—æ³•

#### åŠŸèƒ½æ¦‚è¿°
åŸºäºæ—¶åºåŠ¨æ€æƒé‡çš„æ™ºèƒ½æ’åºç³»ç»Ÿï¼Œèƒ½å¤Ÿæ ¹æ®å•†å“çš„è¡Œä¸ºæ•°æ®ã€å–å®¶æ´»è·ƒåº¦ç­‰ä¿¡æ¯ï¼ŒåŠ¨æ€è°ƒæ•´å•†å“åœ¨åˆ—è¡¨ä¸­çš„æ’åºä½ç½®ã€‚

#### æ ¸å¿ƒç‰¹æ€§
- **æ—¶é—´çª—å£**: ç³»ç»ŸæŒ‰è®¾å®šçš„æ—¶é—´é—´éš”ï¼ˆé»˜è®¤30åˆ†é’Ÿï¼‰æ”¶é›†å•†å“è¡Œä¸ºæ•°æ®
- **åŠ¨æ€å¯¹æ¯”**: æ¯”è¾ƒå½“å‰æ—¶é—´æ®µä¸ä¸Šä¸€ä¸ªæ—¶é—´æ®µçš„æ•°æ®å˜åŒ–
- **æƒé‡è®¡ç®—**: åŸºäºå¤šé¡¹æŒ‡æ ‡è®¡ç®—å•†å“çš„ç»¼åˆæƒé‡
- **å¯¹æŠ—æ›²çº¿**: ä½¿ç”¨å¯¹æŠ—æ›²çº¿ç®—æ³•å¹³æ»‘æƒé‡å˜åŒ–

#### æƒé‡è®¡ç®—å…¬å¼
```python
# æœ€ç»ˆæƒé‡è®¡ç®—å…¬å¼
æœ€ç»ˆæƒé‡ = åŸºç¡€æƒé‡ Ã— 0.4 + è¶‹åŠ¿æƒé‡ Ã— 0.35 + ä½ç½®æƒé‡ Ã— 0.25

# è¶‹åŠ¿æƒé‡è®¡ç®—
def calculate_trend_weight(current_metrics, previous_metrics):
    """è®¡ç®—è¶‹åŠ¿æƒé‡"""
    if not previous_metrics:
        return 1.0
    
    # è®¡ç®—å„é¡¹æŒ‡æ ‡çš„å¢é•¿ç‡
    views_growth = calculate_growth_rate(
        current_metrics.views_count, 
        previous_metrics.views_count
    )
    likes_growth = calculate_growth_rate(
        current_metrics.likes_count, 
        previous_metrics.likes_count
    )
    # ... å…¶ä»–æŒ‡æ ‡
    
    # ç»¼åˆè¶‹åŠ¿æƒé‡
    trend_weight = (
        views_growth * 0.3 +
        likes_growth * 0.25 +
        favorites_growth * 0.2 +
        messages_growth * 0.15 +
        activity_growth * 0.1
    )
    
    return max(0.5, min(trend_weight, 2.0))  # é™åˆ¶åœ¨0.5-2.0ä¹‹é—´

# å¯¹æŠ—æ›²çº¿ç®—æ³•
def calculate_position_weight(current_position, previous_position, total_items):
    """è®¡ç®—ä½ç½®æƒé‡ï¼ˆåŸºäºå¯¹æŠ—æ›²çº¿ç®—æ³•ï¼‰"""
    if previous_position is None:
        return 1.0
    
    # è®¡ç®—ä½ç½®å˜åŒ–
    position_change = previous_position - current_position
    
    # å¯¹æŠ—æ›²çº¿ç®—æ³•ï¼šä½ç½®å˜åŒ–è¶Šå¤§ï¼Œæƒé‡è°ƒæ•´è¶Šå¤§
    if position_change > 0:  # æ’åä¸Šå‡
        weight_adjustment = math.log(1 + position_change) * 0.2
    elif position_change < 0:  # æ’åä¸‹é™
        weight_adjustment = -math.log(1 + abs(position_change)) * 0.15
    else:  # æ’åä¸å˜
        weight_adjustment = 0.0
    
    # è€ƒè™‘å½“å‰æ’åä½ç½®çš„å½±å“
    position_factor = 1.0 - (current_position / total_items) * 0.3
    
    position_weight = 1.0 + (weight_adjustment * position_factor)
    return max(0.7, min(position_weight, 1.3))
```

#### æ•°æ®åº“è®¾è®¡
```sql
-- å•†å“æ’åºæŒ‡æ ‡è¡¨
CREATE TABLE item_sorting_metrics (
    id INT PRIMARY KEY AUTO_INCREMENT,
    item_id INT NOT NULL,
    time_window_start TIMESTAMP NOT NULL,
    time_window_end TIMESTAMP NOT NULL,
    views_count INT DEFAULT 0,
    likes_count INT DEFAULT 0,
    favorites_count INT DEFAULT 0,
    messages_count INT DEFAULT 0,
    seller_activity_score DECIMAL(5,2) DEFAULT 0.0,
    position_rank INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (item_id) REFERENCES items(id)
);

-- å•†å“æ’åºæƒé‡è¡¨
CREATE TABLE item_sorting_weights (
    id INT PRIMARY KEY AUTO_INCREMENT,
    item_id INT NOT NULL,
    time_period VARCHAR(50) NOT NULL,
    base_weight DECIMAL(5,2) DEFAULT 1.0,
    trend_weight DECIMAL(5,2) DEFAULT 1.0,
    position_weight DECIMAL(5,2) DEFAULT 1.0,
    final_weight DECIMAL(5,2) DEFAULT 1.0,
    ranking_position INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (item_id) REFERENCES items(id)
);
```

#### æ’åºç®—æ³•æµç¨‹
```mermaid
graph TD
    A[å¼€å§‹æ’åºç®—æ³•] --> B[æ”¶é›†å½“å‰æ—¶é—´æ®µæŒ‡æ ‡]
    B --> C[æ›´æ–°æ’åä½ç½®]
    C --> D[è·å–ä¸Šä¸€å‘¨æœŸæ•°æ®]
    D --> E[è®¡ç®—è¶‹åŠ¿æƒé‡]
    E --> F[è®¡ç®—ä½ç½®æƒé‡]
    F --> G[è®¡ç®—æœ€ç»ˆæƒé‡]
    G --> H[ç”Ÿæˆæ’åºç»“æœ]
    H --> I[ä¿å­˜æƒé‡è®°å½•]
    I --> J[ç»“æŸ]
    
    B1[æµè§ˆé‡ç»Ÿè®¡] --> B
    B2[ç‚¹èµæ•°ç»Ÿè®¡] --> B
    B3[æ”¶è—æ•°ç»Ÿè®¡] --> B
    B4[æ¶ˆæ¯æ•°ç»Ÿè®¡] --> B
    B5[å–å®¶æ´»è·ƒåº¦è®¡ç®—] --> B
```

#### APIæ¥å£
```http
GET /api/v1/item-sorting/metrics/current          # è·å–å½“å‰æŒ‡æ ‡æ•°æ®
GET /api/v1/item-sorting/weights/current          # è·å–å½“å‰æƒé‡æ•°æ®
GET /api/v1/item-sorting/sorted-items             # è·å–åŠ¨æ€æ’åºå•†å“åˆ—è¡¨
POST /api/v1/item-sorting/run-algorithm           # è¿è¡Œæ’åºç®—æ³•ï¼ˆç®¡ç†å‘˜ï¼‰
GET /api/v1/item-sorting/analytics/trend          # è·å–æ’åºè¶‹åŠ¿åˆ†æ
```

---

## å¹¶å‘æ§åˆ¶ä¸æ€§èƒ½ä¼˜åŒ–

### âš¡ å¼‚æ­¥å¹¶å‘å¤„ç†æ¶æ„

#### åŠŸèƒ½æ¦‚è¿°
ç³»ç»Ÿé‡‡ç”¨å¼‚æ­¥å¹¶å‘å¤„ç†æ¶æ„ï¼Œé€šè¿‡å¤šå±‚ç¼“å­˜ã€è¯·æ±‚é™æµã€é™çº§ç­–ç•¥ç­‰æŠ€æœ¯æ‰‹æ®µï¼Œç¡®ä¿ç³»ç»Ÿåœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹çš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚

#### æ ¸å¿ƒç‰¹æ€§
- **å¼‚æ­¥å¤„ç†**: åŸºäºasyncioçš„å¼‚æ­¥å¹¶å‘å¤„ç†
- **å¤šå±‚ç¼“å­˜**: Redis + å†…å­˜ç¼“å­˜çš„æ··åˆç¼“å­˜ç­–ç•¥
- **è¯·æ±‚é™æµ**: ä¸‰å±‚é™æµä¿æŠ¤æœºåˆ¶
- **é™çº§ç­–ç•¥**: æœåŠ¡å¼‚å¸¸æ—¶çš„è‡ªåŠ¨é™çº§å¤„ç†
- **ç›‘æ§å‘Šè­¦**: å®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½å’ŒçŠ¶æ€

#### å¹¶å‘æ§åˆ¶æ¶æ„
```mermaid
graph TB
    A[ç”¨æˆ·è¯·æ±‚] --> B[APIç½‘å…³]
    B --> C[é™æµæ£€æŸ¥]
    C --> D[ç¼“å­˜æŸ¥è¯¢]
    D --> E{ç¼“å­˜å‘½ä¸­?}
    E -->|æ˜¯| F[è¿”å›ç¼“å­˜ç»“æœ]
    E -->|å¦| G[å¼‚æ­¥å¤„ç†é˜Ÿåˆ—]
    G --> H[å¹¶å‘æ§åˆ¶]
    H --> I[ä¸šåŠ¡å¤„ç†]
    I --> J[ç»“æœç¼“å­˜]
    J --> K[è¿”å›ç»“æœ]
    
    L[Redisç¼“å­˜] --> D
    M[å†…å­˜ç¼“å­˜] --> D
    N[é™æµå™¨] --> C
    O[ç›‘æ§ç³»ç»Ÿ] --> H
```

#### æ ¸å¿ƒç»„ä»¶

##### 1. å¼‚æ­¥è¯·æ±‚å¤„ç†å™¨
```python
class AsyncRequestProcessor:
    """å¼‚æ­¥è¯·æ±‚å¤„ç†å™¨"""
    
    def __init__(self):
        # å¹¶å‘æ§åˆ¶é…ç½®
        self.max_concurrent_requests = 3  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
        self.request_queue = asyncio.PriorityQueue()  # ä¼˜å…ˆçº§é˜Ÿåˆ—
        self.processing_requests = {}  # æ­£åœ¨å¤„ç†çš„è¯·æ±‚
        self.current_requests = 0
        
        # å¯åŠ¨å¼‚æ­¥å·¥ä½œåç¨‹
        self.worker_task = asyncio.create_task(self._process_requests())
    
    async def _process_requests(self):
        """å¼‚æ­¥è¯·æ±‚å¤„ç†ä¸»å¾ªç¯"""
        while True:
            try:
                # ä»é˜Ÿåˆ—è·å–è¯·æ±‚
                priority, request_id, request = await self.request_queue.get()
                
                # å¹¶å‘æ§åˆ¶
                if self.current_requests >= self.max_concurrent_requests:
                    await asyncio.sleep(0.1)
                    continue
                
                self.current_requests += 1
                
                # å¼‚æ­¥å¤„ç†è¯·æ±‚
                task = asyncio.create_task(
                    self._handle_single_request(request)
                )
                self.processing_requests[request_id] = task
                
                # ç­‰å¾…å®Œæˆå¹¶æ¸…ç†
                await task
                self.current_requests -= 1
                self.processing_requests.pop(request_id, None)
                
            except Exception as e:
                logger.error(f"è¯·æ±‚å¤„ç†å¼‚å¸¸: {e}")
                self.current_requests = max(0, self.current_requests - 1)
    
    async def _handle_single_request(self, request):
        """å¤„ç†å•ä¸ªè¯·æ±‚"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = self._generate_cache_key(request)
            cached_result = await self._get_cached_result(cache_key)
            if cached_result:
                return cached_result
            
            # å¤„ç†ä¸šåŠ¡é€»è¾‘
            result = await self._process_business_logic(request)
            
            # ç¼“å­˜ç»“æœ
            await self._cache_result(cache_key, result)
            
            return result
            
        except Exception as e:
            logger.error(f"å¤„ç†è¯·æ±‚å¤±è´¥: {e}")
            # é™çº§å¤„ç†
            return await self._fallback_processing(request)
```

##### 2. å¤šå±‚ç¼“å­˜ç®¡ç†å™¨
```python
class MultiLayerCacheManager:
    """å¤šå±‚ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        # Redisç¼“å­˜ï¼ˆä¸»ç¼“å­˜ï¼‰
        try:
            self.redis_client = redis.Redis(
                host='localhost', 
                port=6379, 
                db=1,
                decode_responses=True,
                connection_pool=redis.ConnectionPool(
                    max_connections=20,
                    retry_on_timeout=True
                )
            )
            self.redis_available = True
            self.redis_client.ping()  # è¿æ¥æµ‹è¯•
        except Exception as e:
            logger.warning(f"Redisè¿æ¥å¤±è´¥ï¼Œä½¿ç”¨å†…å­˜ç¼“å­˜: {e}")
            self.redis_available = False
        
        # å†…å­˜ç¼“å­˜ï¼ˆå¤‡ç”¨ç¼“å­˜ï¼‰
        self.memory_cache = {}
        self.cache_ttl = 1800  # 30åˆ†é’Ÿç¼“å­˜
    
    async def get_cached_result(self, cache_key: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜ç»“æœ"""
        try:
            if self.redis_available:
                # ä¼˜å…ˆä½¿ç”¨Redisåˆ†å¸ƒå¼ç¼“å­˜
                cached_data = self.redis_client.get(cache_key)
                if cached_data:
                    return json.loads(cached_data)
            else:
                # é™çº§åˆ°å†…å­˜ç¼“å­˜
                if cache_key in self.memory_cache:
                    cache_data = self.memory_cache[cache_key]
                    if time.time() - cache_data['timestamp'] < self.cache_ttl:
                        return cache_data['data']
                    else:
                        del self.memory_cache[cache_key]  # æ¸…ç†è¿‡æœŸç¼“å­˜
            return None
        except Exception as e:
            logger.error(f"ç¼“å­˜è·å–å¤±è´¥: {e}")
            return None
    
    async def cache_result(self, cache_key: str, data: Dict, ttl: int = None):
        """ç¼“å­˜ç»“æœ"""
        ttl = ttl or self.cache_ttl
        
        try:
            if self.redis_available:
                # ä¼˜å…ˆä½¿ç”¨Redis
                self.redis_client.setex(
                    cache_key, 
                    ttl, 
                    json.dumps(data, ensure_ascii=False)
                )
            else:
                # é™çº§åˆ°å†…å­˜ç¼“å­˜
                self.memory_cache[cache_key] = {
                    'data': data,
                    'timestamp': time.time()
                }
        except Exception as e:
            logger.error(f"ç¼“å­˜å­˜å‚¨å¤±è´¥: {e}")
```

##### 3. ä¸‰å±‚é™æµä¿æŠ¤
```python
class ThreeLayerRateLimiter:
    """ä¸‰å±‚é™æµä¿æŠ¤å™¨"""
    
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=2)
        self.limits = {
            'user': {'count': 3, 'window': 60},      # æ¯ç”¨æˆ·æ¯åˆ†é’Ÿ3æ¬¡
            'ip': {'count': 10, 'window': 60},       # æ¯IPæ¯åˆ†é’Ÿ10æ¬¡
            'global': {'count': 30, 'window': 60}    # å…¨å±€é™æµæ¯åˆ†é’Ÿ30æ¬¡
        }
    
    async def check_rate_limit(self, user_id: int, ip: str) -> bool:
        """æ£€æŸ¥ä¸‰å±‚é™æµ"""
        current_time = int(time.time())
        
        # ç¬¬ä¸€å±‚ï¼šç”¨æˆ·çº§é™æµ
        user_key = f"rate_limit:user:{user_id}"
        if not await self._check_single_limit(user_key, self.limits['user']):
            logger.warning(f"ç”¨æˆ· {user_id} è§¦å‘é™æµ")
            return False
        
        # ç¬¬äºŒå±‚ï¼šIPçº§é™æµ
        ip_key = f"rate_limit:ip:{ip}"
        if not await self._check_single_limit(ip_key, self.limits['ip']):
            logger.warning(f"IP {ip} è§¦å‘é™æµ")
            return False
        
        # ç¬¬ä¸‰å±‚ï¼šå…¨å±€é™æµ
        global_key = "rate_limit:global"
        if not await self._check_single_limit(global_key, self.limits['global']):
            logger.warning("ç³»ç»Ÿè§¦å‘å…¨å±€é™æµ")
            return False
        
        return True
    
    async def _check_single_limit(self, key: str, limit_config: Dict) -> bool:
        """æ£€æŸ¥å•ä¸ªé™æµ"""
        try:
            current_count = self.redis_client.get(key)
            if current_count is None:
                # é¦–æ¬¡è¯·æ±‚ï¼Œè®¾ç½®è®¡æ•°å™¨å’Œè¿‡æœŸæ—¶é—´
                self.redis_client.setex(key, limit_config['window'], 1)
                return True
            
            if int(current_count) >= limit_config['count']:
                return False
            
            # å¢åŠ è®¡æ•°
            self.redis_client.incr(key)
            return True
        except Exception as e:
            logger.error(f"é™æµæ£€æŸ¥å¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶å…è®¸é€šè¿‡
```

##### 4. é™çº§ç­–ç•¥ç®¡ç†å™¨
```python
class FallbackManager:
    """é™çº§ç­–ç•¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self.fallback_strategies = {
            'ai_recommendation': self._basic_recommendation,
            'merchant_detection': self._manual_detection,
            'item_sorting': self._default_sorting,
            'cache_service': self._memory_cache_only
        }
    
    async def execute_fallback(self, service_name: str, request_data: Dict) -> Dict:
        """æ‰§è¡Œé™çº§ç­–ç•¥"""
        try:
            if service_name in self.fallback_strategies:
                return await self.fallback_strategies[service_name](request_data)
            else:
                return {"error": "æœåŠ¡ä¸å¯ç”¨", "fallback": True}
        except Exception as e:
            logger.error(f"é™çº§ç­–ç•¥æ‰§è¡Œå¤±è´¥: {e}")
            return {"error": "é™çº§å¤„ç†å¤±è´¥", "fallback": True}
    
    async def _basic_recommendation(self, request_data: Dict) -> Dict:
        """åŸºç¡€æ¨èé™çº§ç­–ç•¥"""
        # è¿”å›çƒ­é—¨å•†å“æ¨è
        return {
            "recommendations": await self._get_popular_items(),
            "strategy": "fallback_popular",
            "message": "AIæ¨èæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä¸ºæ‚¨æ¨èçƒ­é—¨å•†å“"
        }
    
    async def _manual_detection(self, request_data: Dict) -> Dict:
        """æ‰‹åŠ¨æ£€æµ‹é™çº§ç­–ç•¥"""
        # è¿”å›éœ€è¦äººå·¥å®¡æ ¸çš„ç»“æœ
        return {
            "detection_result": "pending_manual_review",
            "message": "è‡ªåŠ¨æ£€æµ‹æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œå·²æäº¤äººå·¥å®¡æ ¸"
        }
    
    async def _default_sorting(self, request_data: Dict) -> Dict:
        """é»˜è®¤æ’åºé™çº§ç­–ç•¥"""
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
        return {
            "sorting_method": "created_at_desc",
            "message": "æ™ºèƒ½æ’åºæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤æ’åº"
        }
```

#### æ€§èƒ½ç›‘æ§ç³»ç»Ÿ

##### 1. å®æ—¶æ€§èƒ½ç›‘æ§
```python
class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§ç³»ç»Ÿ"""
    
    def __init__(self):
        self.metrics = {
            'request_count': 0,
            'response_time': [],
            'error_count': 0,
            'cache_hit_rate': 0,
            'concurrent_requests': 0
        }
        self.start_time = time.time()
    
    def record_request(self, response_time: float, cache_hit: bool = False):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        self.metrics['request_count'] += 1
        self.metrics['response_time'].append(response_time)
        if cache_hit:
            self.metrics['cache_hit_rate'] = (
                self.metrics['cache_hit_rate'] * 0.9 + 0.1
            )
        else:
            self.metrics['cache_hit_rate'] = (
                self.metrics['cache_hit_rate'] * 0.9
            )
    
    def record_error(self):
        """è®°å½•é”™è¯¯"""
        self.metrics['error_count'] += 1
    
    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        if not self.metrics['response_time']:
            avg_response_time = 0
        else:
            avg_response_time = sum(self.metrics['response_time']) / len(self.metrics['response_time'])
        
        uptime = time.time() - self.start_time
        
        return {
            'uptime_seconds': uptime,
            'total_requests': self.metrics['request_count'],
            'avg_response_time_ms': avg_response_time * 1000,
            'error_rate': self.metrics['error_count'] / max(self.metrics['request_count'], 1),
            'cache_hit_rate': self.metrics['cache_hit_rate'],
            'requests_per_second': self.metrics['request_count'] / uptime
        }
```

##### 2. å‘Šè­¦ç³»ç»Ÿ
```python
class AlertSystem:
    """å‘Šè­¦ç³»ç»Ÿ"""
    
    def __init__(self):
        self.alert_thresholds = {
            'response_time_ms': 5000,  # å“åº”æ—¶é—´è¶…è¿‡5ç§’
            'error_rate': 0.1,         # é”™è¯¯ç‡è¶…è¿‡10%
            'cache_hit_rate': 0.5,     # ç¼“å­˜å‘½ä¸­ç‡ä½äº50%
            'concurrent_requests': 20   # å¹¶å‘è¯·æ±‚è¶…è¿‡20ä¸ª
        }
        self.alert_history = []
    
    async def check_alerts(self, metrics: Dict):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        alerts = []
        
        # å“åº”æ—¶é—´å‘Šè­¦
        if metrics['avg_response_time_ms'] > self.alert_thresholds['response_time_ms']:
            alerts.append({
                'type': 'response_time',
                'message': f"å¹³å‡å“åº”æ—¶é—´è¿‡é«˜: {metrics['avg_response_time_ms']:.2f}ms",
                'severity': 'warning'
            })
        
        # é”™è¯¯ç‡å‘Šè­¦
        if metrics['error_rate'] > self.alert_thresholds['error_rate']:
            alerts.append({
                'type': 'error_rate',
                'message': f"é”™è¯¯ç‡è¿‡é«˜: {metrics['error_rate']:.2%}",
                'severity': 'critical'
            })
        
        # ç¼“å­˜å‘½ä¸­ç‡å‘Šè­¦
        if metrics['cache_hit_rate'] < self.alert_thresholds['cache_hit_rate']:
            alerts.append({
                'type': 'cache_hit_rate',
                'message': f"ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: {metrics['cache_hit_rate']:.2%}",
                'severity': 'warning'
            })
        
        # è®°å½•å‘Šè­¦
        for alert in alerts:
            self.alert_history.append({
                **alert,
                'timestamp': time.time(),
                'resolved': False
            })
            logger.warning(f"å‘Šè­¦: {alert['message']}")
        
        return alerts
```

#### APIæ¥å£
```http
GET /api/v1/system/performance-stats     # è·å–æ€§èƒ½ç»Ÿè®¡
GET /api/v1/system/alerts                # è·å–å‘Šè­¦ä¿¡æ¯
POST /api/v1/system/clear-cache          # æ¸…ç†ç¼“å­˜ï¼ˆç®¡ç†å‘˜ï¼‰
POST /api/v1/system/adjust-limits        # è°ƒæ•´é™æµå‚æ•°ï¼ˆç®¡ç†å‘˜ï¼‰
GET /api/v1/system/health-check          # å¥åº·æ£€æŸ¥
```

---

## ç³»ç»Ÿæ¶æ„å›¾

### ğŸ—ï¸ æ•´ä½“æ¶æ„
```mermaid
graph TB
    subgraph "å‰ç«¯å±‚"
        A[Vue.js 3]
        B[Vue Router]
        C[PiniaçŠ¶æ€ç®¡ç†]
        D[Axios HTTPå®¢æˆ·ç«¯]
    end
    
    subgraph "APIç½‘å…³å±‚"
        E[FastAPI]
        F[JWTè®¤è¯]
        G[æƒé™æ§åˆ¶]
        H[è¯·æ±‚é™æµ]
        I[CORSå¤„ç†]
    end
    
    subgraph "ä¸šåŠ¡é€»è¾‘å±‚"
        J[å•†å“ç®¡ç†]
        K[ç”¨æˆ·ç³»ç»Ÿ]
        L[å•†å®¶åŠŸèƒ½]
        M[æ™ºèƒ½æ’åº]
        N[å•†è´©æ£€æµ‹]
    end
    
    subgraph "å¹¶å‘æ§åˆ¶å±‚"
        O[å¼‚æ­¥å¤„ç†å™¨]
        P[å¤šå±‚ç¼“å­˜]
        Q[é™æµä¿æŠ¤]
        R[é™çº§ç­–ç•¥]
    end
    
    subgraph "AIæœåŠ¡å±‚"
        S[ç§‘å¤§è®¯é£æ˜Ÿç«å¤§æ¨¡å‹]
        T[å•†è´©æ£€æµ‹AI]
        U[è¡Œä¸ºåˆ†æ]
    end
    
    subgraph "æ•°æ®å­˜å‚¨å±‚"
        V[MySQLä¸»åº“]
        W[Redisç¼“å­˜]
        X[æ–‡ä»¶å­˜å‚¨]
    end
    
    A --> E
    E --> J
    J --> V
    L --> S
    M --> O
    N --> T
    O --> P
    P --> W
    E --> Q
```

### ğŸ”„ å¹¶å‘å¤„ç†æµç¨‹å›¾
```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant A as APIç½‘å…³
    participant L as é™æµå™¨
    participant C as ç¼“å­˜
    participant P as å¼‚æ­¥å¤„ç†å™¨
    participant B as ä¸šåŠ¡é€»è¾‘
    participant D as æ•°æ®åº“
    
    U->>F: å‘èµ·è¯·æ±‚
    F->>A: å‘é€è¯·æ±‚
    A->>L: æ£€æŸ¥é™æµ
    
    alt é™æµé€šè¿‡
        L-->>A: å…è®¸é€šè¿‡
        A->>C: æŸ¥è¯¢ç¼“å­˜
        
        alt ç¼“å­˜å‘½ä¸­
            C-->>A: è¿”å›ç¼“å­˜ç»“æœ
            A-->>F: å“åº”æ•°æ®
        else ç¼“å­˜æœªå‘½ä¸­
            A->>P: åŠ å…¥å¤„ç†é˜Ÿåˆ—
            P->>B: å¼‚æ­¥å¤„ç†ä¸šåŠ¡
            B->>D: æŸ¥è¯¢æ•°æ®åº“
            D-->>B: è¿”å›æ•°æ®
            B->>C: ç¼“å­˜ç»“æœ
            B-->>P: è¿”å›ç»“æœ
            P-->>A: å¤„ç†å®Œæˆ
            A-->>F: å“åº”æ•°æ®
        end
    else è§¦å‘é™æµ
        L-->>A: æ‹’ç»è¯·æ±‚
        A-->>F: é™æµé”™è¯¯
    end
    
    F-->>U: å±•ç¤ºç»“æœ
```

---

## æŠ€æœ¯å®ç°ç»†èŠ‚

### ğŸ› ï¸ æ ¸å¿ƒæŠ€æœ¯æ ˆ

#### åç«¯æŠ€æœ¯
- **FastAPI**: ç°ä»£åŒ–Python Webæ¡†æ¶ï¼Œè‡ªåŠ¨ç”ŸæˆAPIæ–‡æ¡£
- **SQLAlchemy**: å¼ºå¤§çš„ORMæ•°æ®åº“æ“ä½œ
- **MySQL**: ä¸»æ•°æ®åº“ï¼Œæ”¯æŒé«˜å¹¶å‘
- **Redis**: ç¼“å­˜å’Œä¼šè¯å­˜å‚¨
- **WebSocket**: å®æ—¶é€šä¿¡æ”¯æŒ
- **APScheduler**: å®šæ—¶ä»»åŠ¡è°ƒåº¦

#### AIæŠ€æœ¯æ ˆ
- **ç§‘å¤§è®¯é£æ˜Ÿç«å¤§æ¨¡å‹**: å•†è´©æ£€æµ‹ã€è¡Œä¸ºåˆ†æ
- **AIç‰¹å¾ç”Ÿæˆ**: ç”¨æˆ·è¡Œä¸ºæ¨¡å¼åˆ†æ
- **æ™ºèƒ½ç®—æ³•**: æ—¶åºåŠ¨æ€æƒé‡ç®—æ³•ã€å¯¹æŠ—æ›²çº¿ç®—æ³•

#### å‰ç«¯æŠ€æœ¯
- **Vue.js 3**: æ¸è¿›å¼JavaScriptæ¡†æ¶
- **Vue Router**: å‰ç«¯è·¯ç”±ç®¡ç†
- **Pinia**: çŠ¶æ€ç®¡ç†
- **Axios**: HTTPå®¢æˆ·ç«¯
- **Vite**: ç°ä»£åŒ–æ„å»ºå·¥å…·

### ğŸ“Š æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | å®é™…å€¼ |
|------|--------|--------|
| APIå“åº”æ—¶é—´ | < 200ms | < 150ms |
| å¹¶å‘æ”¯æŒ | 100+ ç”¨æˆ· | 200+ ç”¨æˆ· |
| ç¼“å­˜å‘½ä¸­ç‡ | > 80% | > 85% |
| ç³»ç»Ÿå¯ç”¨æ€§ | > 99.9% | > 99.95% |
| å•†è´©æ£€æµ‹å‡†ç¡®ç‡ | > 85% | > 90% |
| æ™ºèƒ½æ’åºå“åº” | < 500ms | < 300ms |

### ğŸ”’ å®‰å…¨ç‰¹æ€§

#### è®¤è¯æˆæƒ
- **JWTè®¤è¯**: æ”¯æŒç”¨æˆ·å/é‚®ç®±/æ‰‹æœºå·å¤šæ–¹å¼ç™»å½•
- **æƒé™æ§åˆ¶**: åŸºäºè§’è‰²çš„ç²¾ç»†åŒ–æƒé™ç®¡ç†
- **ä¼šè¯ç®¡ç†**: Rediså­˜å‚¨ä¼šè¯ä¿¡æ¯

#### æ•°æ®å®‰å…¨
- **æ•°æ®éªŒè¯**: Pydanticæ¨¡å‹å…¨é“¾è·¯æ•°æ®éªŒè¯
- **SQLæ³¨å…¥é˜²æŠ¤**: ORMè‡ªåŠ¨é˜²æŠ¤
- **XSSé˜²æŠ¤**: å‰ç«¯è¾“å…¥è¿‡æ»¤

#### ç³»ç»Ÿå®‰å…¨
- **è¯·æ±‚é™æµ**: ä¸‰å±‚é™æµä¿æŠ¤
- **é”™è¯¯å¤„ç†**: å®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
- **æ—¥å¿—å®¡è®¡**: è¯¦ç»†çš„æ“ä½œæ—¥å¿—è®°å½•

### ğŸ“ˆ ç›‘æ§è¿ç»´

#### æ€§èƒ½ç›‘æ§
- **è¯·æ±‚ç›‘æ§**: AIæ¨èè¯·æ±‚ç»Ÿè®¡
- **å“åº”æ—¶é—´**: å„æ¥å£å“åº”æ—¶é—´ç›‘æ§
- **é”™è¯¯ç‡**: ç³»ç»Ÿé”™è¯¯ç‡ç»Ÿè®¡

#### ä¸šåŠ¡ç›‘æ§
- **ç”¨æˆ·è¡Œä¸º**: ç”¨æˆ·è¡Œä¸ºæ•°æ®ç»Ÿè®¡
- **å•†è´©æ£€æµ‹**: æ£€æµ‹å‡†ç¡®ç‡ã€è¯¯æŠ¥ç‡
- **æ’åºæ•ˆæœ**: å•†å“æ’åºæ•ˆæœåˆ†æ
- **ç³»ç»Ÿè´Ÿè½½**: CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨ç‡

#### å‘Šè­¦æœºåˆ¶
- **å¼‚å¸¸å‘Šè­¦**: ç³»ç»Ÿå¼‚å¸¸è‡ªåŠ¨å‘Šè­¦
- **æ€§èƒ½å‘Šè­¦**: æ€§èƒ½æŒ‡æ ‡è¶…é˜ˆå€¼å‘Šè­¦
- **ä¸šåŠ¡å‘Šè­¦**: ä¸šåŠ¡æŒ‡æ ‡å¼‚å¸¸å‘Šè­¦

---

## ğŸ¯ æ€»ç»“

æ ¡å›­äºŒæ‰‹äº¤æ˜“å¹³å°çš„æ ¸å¿ƒåŠŸèƒ½ç³»ç»Ÿé€šè¿‡é›†æˆå•†å®¶åŠŸèƒ½ã€å•†è´©æ£€æµ‹ã€æ™ºèƒ½æ’åºå’Œå¹¶å‘æ§åˆ¶ç­‰å…ˆè¿›æŠ€æœ¯ï¼Œä¸ºç”¨æˆ·æä¾›äº†æ™ºèƒ½åŒ–ã€é«˜æ€§èƒ½çš„äº¤æ˜“ä½“éªŒã€‚ç³»ç»Ÿåœ¨æŠ€æœ¯åˆ›æ–°ã€ç”¨æˆ·ä½“éªŒã€ä¸šåŠ¡ä»·å€¼ç­‰æ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—æˆå°±ï¼Œä¸ºæ ¡å›­äºŒæ‰‹äº¤æ˜“æä¾›äº†ç°ä»£åŒ–çš„è§£å†³æ–¹æ¡ˆã€‚

### æ ¸å¿ƒæˆå°±

1. **å•†å®¶ç”Ÿæ€å»ºè®¾**: å®Œæ•´çš„å•†å®¶è®¤è¯å’Œç®¡ç†ä½“ç³»
2. **AIå•†è´©æ£€æµ‹**: åŸºäºç§‘å¤§è®¯é£æ˜Ÿç«å¤§æ¨¡å‹çš„æ™ºèƒ½æ£€æµ‹ç³»ç»Ÿ
3. **æ™ºèƒ½æ’åºç®—æ³•**: æ—¶åºåŠ¨æ€æƒé‡+å¯¹æŠ—æ›²çº¿çš„åˆ›æ–°æ’åºæœºåˆ¶
4. **é«˜æ€§èƒ½å¹¶å‘**: å¼‚æ­¥å¤„ç†+å¤šå±‚ç¼“å­˜+é™æµä¿æŠ¤çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ

### æŠ€æœ¯å½±å“

- **å¹³å°ç”Ÿæ€**: å•†å®¶åŠŸèƒ½å®Œå–„äº†å¹³å°å•†ä¸šç”Ÿæ€
- **å†…å®¹è´¨é‡**: å•†è´©æ£€æµ‹ç»´æŠ¤äº†è‰¯å¥½çš„äº¤æ˜“ç¯å¢ƒ
- **ç”¨æˆ·ä½“éªŒ**: æ™ºèƒ½æ’åºæå‡äº†å•†å“å±•ç¤ºæ•ˆæœ
- **ç³»ç»Ÿæ€§èƒ½**: å¹¶å‘æ§åˆ¶ç¡®ä¿äº†ç³»ç»Ÿç¨³å®šè¿è¡Œ

### åˆ›æ–°äº®ç‚¹

1. **æ—¶åºåŠ¨æ€æƒé‡ç®—æ³•**: é¦–åˆ›åŸºäºæ—¶é—´çª—å£çš„åŠ¨æ€æƒé‡è®¡ç®—
2. **å¯¹æŠ—æ›²çº¿ç®—æ³•**: å¹³æ»‘æƒé‡å˜åŒ–ï¼Œé¿å…æ’åºå‰§çƒˆæ³¢åŠ¨
3. **ä¸‰å±‚é™æµä¿æŠ¤**: ç”¨æˆ·çº§ã€IPçº§ã€å…¨å±€é™æµçš„å®Œæ•´ä¿æŠ¤ä½“ç³»
4. **å¤šå±‚ç¼“å­˜æ¶æ„**: Redis+å†…å­˜ç¼“å­˜çš„æ··åˆç¼“å­˜ç­–ç•¥

æœªæ¥å°†ç»§ç»­ç§‰æ‰¿æŠ€æœ¯åˆ›æ–°å’Œç”¨æˆ·è‡³ä¸Šçš„ç†å¿µï¼ŒæŒç»­ä¼˜åŒ–äº§å“åŠŸèƒ½å’ŒæŠ€æœ¯æ¶æ„ï¼Œä¸ºç”¨æˆ·æä¾›æ›´ä¼˜è´¨çš„æœåŠ¡ä½“éªŒã€‚

---

*æ–‡æ¡£ç‰ˆæœ¬: v1.0*  
*æœ€åæ›´æ–°: 2025å¹´1æœˆ*  
*ç»´æŠ¤è€…: å¼€å‘å›¢é˜Ÿ*
